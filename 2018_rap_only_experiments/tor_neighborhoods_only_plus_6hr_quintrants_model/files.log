$ ruby make_grib_file_list.rb > tor_neighborhoods_only_plus_6hr_model/train.txt
Start year?
2014
Start month?
2
Start day?
26
End year?
2016
End month?
12
End day?
31
Forcast hour (2-18)?
6
Only hours with tornadoes (n/y)?
y
Dev ratio [0.0-1.0]?
0
Test ratio [0.0-1.0]?
0
Subsample ratio [0.0-1.0]? (non-deterministic)
1.0
1658/1658 hours with tornadoes

(need to manually remove headers)

$ ruby make_grib_file_list.rb
Start year?
2017
Start month?
1
Start day?
1
End year?
2017
End month?
12
End day?
31
Forcast hour (2-18)?
6
Only hours with tornadoes (n/y)?
y
Dev ratio [0.0-1.0]?
0.25
Test ratio [0.0-1.0]?
0.25
Subsample ratio [0.0-1.0]? (non-deterministic)
1.0

$ ruby make_grib_file_list.rb
Start year?
2017
Start month?
1
Start day?
1
End year?
2017
End month?
12
End day?
31
Forcast hour (2-18)?
6
Only hours with tornadoes (n/y)?
y
Dev ratio [0.0-1.0]?
0.25
Test ratio [0.0-1.0]?
0.25
Subsample ratio [0.0-1.0]? (non-deterministic)
1.0
# Dev Files
...

# Test Files
...

# Training Files
...

685/685 hours with tornadoes


(make dev.txt/test.txt files manually)
(add training files manually)

So training is 2014-2-26 through 2016 and half the tornado days in 2017.

julia MakeTornadoNeighborhoodsData.jl tor_neighborhoods_only_plus_6hr_quintrants_model/dev.txt


julia MakeTornadoNeighborhoodsData.jl tor_neighborhoods_only_plus_6hr_quintrants_model/train.txt


julia TrainGBM.jl tor_neighborhoods_only_plus_6hr_quintrants_model/lightgbm.jl # LightGBM doesn't need the points shuffled


estimator =
  LightGBM.LGBMBinary(
    num_iterations = 1000,
    min_data_in_leaf = 1000, # 1000 did better than 2000 or 5000, 500 is too small
    # min_sum_hessian_in_leaf = 1000,
    learning_rate = .1, #
    early_stopping_round = 15,
    feature_fraction = .8,
    bagging_fraction = .8, #
    bagging_freq = 5,
    num_leaves = 31, # 15 is too small, 63 is too much
    is_sparse = false,
    max_bin = 255,
    num_threads = 4,
    is_unbalance = false, # if true, changes the label weights so pos/neg classes have same total weight across dataset when computing loss/gradient; causes WAAY too much probability all over
    metric = ["binary_logloss"]
  )

# dev loss 0.06657820990424694

$ ruby read_lightgbm_feature_importance.rb tor_neighborhoods_only_plus_6hr_quintrants_model/lightgbm_loss_0.0665782.model

91	HGT:convective cloud top level:25mi-56mi ring mean
35	LFTX:500-1000 mb:25mi mean
29	CAPE:90-0 mb above ground:point -1hr
25	RH:700 mb:25mi-56mi ring mean
25	4LFTX:180-0 mb above ground:25mi mean storm location -1hr
25	HLCY:3000-0 m above ground:25mi-56mi ring mean
23	HGT:surface:25mi mean storm location -1hr
22	RH:700 mb:25mi-56mi leftward gradient
22	CAPE:90-0 mb above ground:25mi mean
22	PRATE:surface:25mi-56mi ring mean
21	CAPE:90-0 mb above ground:25mi mean -1hr
19	LFTX:500-1000 mb:25mi mean storm location -1hr
19	LFTX:500-1000 mb:point
18	SPFH:80 m above ground:25mi-56mi ring mean
18	CAPE:90-0 mb above ground:25mi-56mi ring mean
17	HLCY:3000-0 m above ground:25mi mean -1hr
17	RGRD:speed m/s 150 mb:25mi-56mi ring mean
16	PLPL:255-0 mb above ground:25mi-56mi ring mean
16	PRES:surface:25mi mean storm location -1hr
16	RGRD:speed m/s 700 mb:25mi-56mi ring mean
16	HLCY:3000-0 m above ground:25mi mean storm location -1hr
15	TMP:100 mb:25mi mean -1hr
15	PWAT:entire atmosphere (considered as a single layer):25mi-56mi ring mean
15	TMP:100 mb:25mi-56mi ring mean
14	TMP:450 mb:25mi mean -1hr
14	RGRD:speed m/s 650 mb:25mi mean
13	RH:500 mb:25mi-56mi ring mean
13	HGT:surface:25mi-56mi ring mean
13	TSTM:angle radians from point storm motion storm motion:25mi-56mi forward gradient
12	RH:750 mb:25mi-56mi ring mean


  LightGBM.LGBMBinary(
    num_iterations = 1000,
    min_data_in_leaf = 1000, # 1000 did better than 2000 or 5000, 500 is too small
    # min_sum_hessian_in_leaf = 1000,
    learning_rate = .08, # .07 did 0.0667, 0.08 did 0.0662411 (worse than .1)
    early_stopping_round = 20,
    feature_fraction = .8,
    bagging_fraction = .8, #
    bagging_freq = 5,
    num_leaves = 31, # 15 is too small, 63 is too much
    is_sparse = false,
    max_bin = 255,
    num_threads = 4,
    is_unbalance = false, # if true, changes the label weights so pos/neg classes have same total weight across dataset when computing loss/gradient; causes WAAY too much probability all over
    metric = ["binary_logloss"]
  )

# dev loss 0.0662411

$ ruby read_lightgbm_feature_importance.rb tor_neighborhoods_only_plus_6hr_quintrants_model/lightgbm_loss_0.0662411.model
13	HGT:convective cloud top level:25mi-56mi ring mean
39	LFTX:500-1000 mb:25mi mean
37	CAPE:90-0 mb above ground:point -1hr
36	HLCY:3000-0 m above ground:25mi-56mi ring mean
32	RH:700 mb:25mi-56mi ring mean
32	LFTX:500-1000 mb:point
30	CAPE:90-0 mb above ground:25mi mean
30	LFTX:500-1000 mb:25mi mean storm location -1hr
28	RH:700 mb:25mi-56mi leftward gradient
27	PRATE:surface:25mi-56mi ring mean
27	RH:400 mb:25mi-56mi ring mean
27	TMP:100 mb:25mi-56mi ring mean
25	PRES:surface:25mi mean storm location -1hr
25	PLPL:255-0 mb above ground:25mi-56mi ring mean
25	HGT:surface:25mi mean storm location -1hr
24	HLCY:3000-0 m above ground:25mi mean -1hr
24	CAPE:90-0 mb above ground:25mi mean -1hr
23	TMP:100 mb:25mi mean storm location -1hr
22	PLPL:255-0 mb above ground:25mi mean storm location -1hr
22	4LFTX:180-0 mb above ground:25mi mean storm location -1hr
22	RH:150 mb:25mi mean storm location -1hr
22	CIN:surface:25mi-56mi ring mean
22	SPFH:80 m above ground:25mi-56mi ring mean
22	CAPE:90-0 mb above ground:25mi-56mi ring mean
21	CIN:90-0 mb above ground:25mi-56mi ring mean
21	TMP:125 mb:25mi-56mi ring mean
21	PRES:80 m above ground:25mi mean storm location -1hr
21	RGRD:speed m/s 150 mb:25mi-56mi ring mean
21	HGT:lowest level of the wet bulb zero:25mi-56mi leftward gradient
20	VVEL:800 mb:25mi-56mi ring mean